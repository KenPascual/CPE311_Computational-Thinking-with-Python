{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5941dc-b31f-4b89-af11-a94c1c2f55cb",
   "metadata": {},
   "source": [
    "# Module 7: Data Wrangling with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204272f-e536-4fc7-8a53-a4c0ed03df70",
   "metadata": {},
   "source": [
    "## CPE311 Computational Thinking with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c8cf3-aca0-4ea8-b404-0f97f4c9d8ea",
   "metadata": {},
   "source": [
    "Submitted by: Pascual, Ken Leonard\n",
    "<br>Performed on: 04/07/2025\n",
    "<br>Submitted on: 04/07/2025\n",
    "<br>Submitted to: Engr. Roman M. Richard\n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637f5e6-b391-4391-9633-cbf5fc962001",
   "metadata": {},
   "source": [
    "# 7.1 Supplementary Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bec544-d9d5-4ebf-bb57-ab7f6ffb04d1",
   "metadata": {},
   "source": [
    "Using the datasets provided, perform the following exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36412380-4e83-403f-852a-883d59ef1e0f",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fcbce-2aee-4972-b188-c2f06dcbdded",
   "metadata": {},
   "source": [
    "We want to look at data for the Facebook, Apple, Amazon, Netflix, and Google (FAANG) stocks, but we were given each as a separate CSV file. Combine them into a single file and store the dataframe of the FAANG data as faang for the rest of the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abe52d-c970-4d60-b093-a19bb2147010",
   "metadata": {},
   "source": [
    "1. Read each file in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad3663d-1b9a-408d-86fd-54228ecb9ed9",
   "metadata": {},
   "source": [
    "2. Add a column to each dataframe, called ticker, indicating the ticker symbol it is for (Apple's is AAPL, for example). This is how you look up a stock. Each file's name is also the ticker symbol, so be sure to capitalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35afa2b-515e-4f0d-af8a-f7bd4a1a1365",
   "metadata": {},
   "source": [
    "3. Append them together into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f4108-a84a-4165-9e62-3934636c6423",
   "metadata": {},
   "source": [
    "4. Save the result in a CSV file called faang.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fcc5c-fc61-413e-be1a-6a9bfe666ff6",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf5da9-efd0-4c1f-a48c-6607cdfe3038",
   "metadata": {},
   "source": [
    "* With faang , use type conversion to change the date column into a datetime and the volume column into integers. Then, sort by date and ticker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21491384-0010-483a-b8f7-f305ff8f02b2",
   "metadata": {},
   "source": [
    "* Find the seven rows with the highest value for the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a438fd-3aca-4bc2-9162-31bdd452f1a9",
   "metadata": {},
   "source": [
    "* Right now, the data is somewhere between long and wide format. Use melt() to make it completely long format.<br>\n",
    "Hint: date and ticker are our ID variables (they uniquely identify each row). We need to melt the rest so that we don't have separate columns for open, high, low, close, and volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deb01d0-f3fa-45bf-8d50-d922672a5186",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6f97a-0442-4e21-8e15-826c9f20340d",
   "metadata": {},
   "source": [
    "* Using web scraping, search for the list of the hospitals, their address, and contact information. Save the list in a new CSV file, hospitals.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d281d30-475c-4f3b-8ae1-79c6b5b8181f",
   "metadata": {},
   "source": [
    "* Using the generated hospitals.csv, convert the CSV file into pandas dataframe. Prepare the data using the necessary preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78ad16-6339-4058-ae43-f63f83a3d740",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98350a63-8e16-46ac-a7c3-2f61852098e0",
   "metadata": {},
   "source": [
    "# 7.2 Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
